{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\User\\Desktop\\MulitAgent_PointAndClick\\deep_q_network.py:20: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import deep_q_network as dqn\n",
    "\n",
    "import math\n",
    "import gym\n",
    "from gym import spaces\n",
    "from gym.utils import seeding\n",
    "import numpy as np\n",
    "\n",
    "import point_and_click_model as pac\n",
    "import modules.motor_control_module as motor\n",
    "import modules.visual_perception_module as visual\n",
    "\n",
    "from collections import deque\n",
    "import os\n",
    "\n",
    "class Env(gym.Env):\n",
    "    \"\"\"\n",
    "    Description:\n",
    "        TBD\n",
    "    Source:\n",
    "        TBD\n",
    "    Observation:\n",
    "        Type: Box(9)\n",
    "        Num\tObservation                 Min         Max\n",
    "        0\tCursor Position X           -1          1 (m)     # Cursor\n",
    "        1\tCursor Position Y           -1          1 (m)\n",
    "        2   Cursor Velocity X           -Inf        Inf (m/s)\n",
    "        3   Cursor Velocity Y           -Inf        Inf (m/s)\n",
    "        4\tTarget Position X           -1          1 (m)     # Target\n",
    "        5\tTarget Position Y           -1          1 (m)\n",
    "        6   Target Velocity X           -0.5        0.5 (m/s)\n",
    "        7   Target Velocity Y           -0.5        0.5 (m/s)\n",
    "        8   Target Radius                0.0096     0.024 (m)\n",
    "        9   Hand Position X             -1.5        1.5 (m)\n",
    "        10  Hand Position Y             -1.5        1.5 (m)\n",
    "\n",
    "    Actions:\n",
    "        Type: Discrete(50)\n",
    "        Num\tAction\n",
    "        // Actions are being changed\n",
    "        0   Th = Tp + 0 s,      Click decision (K) = 0\n",
    "        1   Th = Tp + 0.1 s,    Click decision (K) = 0          : Changing the Th\n",
    "        ...\n",
    "        24  Th = Tp + 2.4 s,    Click decision (K) = 0          : Changing the Th\n",
    "        25  Th = Tp + 0 s,      Click decision (K) = 0          : Changing the Click decision K\n",
    "        26  Th = Tp + 0.1 s,    Click decision (K) = 1          : Changing the Th\n",
    "        ...\n",
    "        48  Th = Tp + 2.3 s,    Click decision (K) = 1          : Changing the Th\n",
    "        49  Th = Tp + 2.4 s,    Click decision (K) = 1          : Changing the Th\n",
    "\n",
    "    Reward:\n",
    "        Click Success Reward (14) - Sum of the acceleration     : When the cursor successes to click and catch the target\n",
    "        Click Failure Reward (-1) - Sum of the acceleration     : When the cursor clicks the target but fails to catch the target\n",
    "        - Sum of the acceleration                               : Any other steps\n",
    "    Starting State:\n",
    "        All observations are assigned a uniform random value in window\n",
    "    Episode Termination:\n",
    "        When the cursor clicks the target\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        # User Parameters for BUMP model\n",
    "        self.Tp = 0.1  # Planning time\n",
    "        self.nc = [0.2, 0.02]  # Motor noise parameter\n",
    "\n",
    "        # User Parameters for ICP model\n",
    "        self.cMu = 0.185\n",
    "        self.cSigma = 0.09015\n",
    "        self.nu = 19.931\n",
    "        self.delta = 0.399\n",
    "        self.fixed = False\n",
    "\n",
    "        # Hand to Mouse Parameters\n",
    "        self.forearm = 0.257\n",
    "        self.mouseGain = 1\n",
    "\n",
    "        # Action Parameters\n",
    "        self.Th = self.Tp + (np.arange(25.0) * 0.1)\n",
    "        self.ThresholdID = (np.arange(2.0) * 1)\n",
    "        self.action_size = len(self.Th) * len(self.ThresholdID)\n",
    "\n",
    "        # Simulation Parameter\n",
    "        self.Interval = 0.05\n",
    "        self.p = 1\n",
    "\n",
    "        # Space Boundary\n",
    "        self.window_width = 0.4608\n",
    "        self.window_height = 0.2592\n",
    "        low = np.array([-1, -1, -np.finfo(np.float32).max, -np.finfo(np.float32).max, -1, -1, -0.5, -0.5, 0.0096, -1, -1])\n",
    "        high = np.array([1, 1, np.finfo(np.float32).max, np.finfo(np.float32).max, 1, 1, 0.5, 0.5, 0.024, 1, 1])\n",
    "\n",
    "        self.action_space = spaces.Discrete(self.action_size)\n",
    "        self.observation_space = spaces.Box(low, high, dtype=np.float32)\n",
    "\n",
    "        self.seed(seed=7)\n",
    "        self.viewer = None\n",
    "        self.state = np.concatenate((self.np_random.uniform(low=0, high=self.window_width, size=(1,)),\n",
    "                                     self.np_random.uniform(low=0, high=self.window_height, size=(1,)),\n",
    "                                     self.np_random.uniform(low=-1, high=1, size=(2,)),\n",
    "                                     self.np_random.uniform(low=0, high=self.window_width, size=(1,)),\n",
    "                                     self.np_random.uniform(low=0, high=self.window_height, size=(1,)),\n",
    "                                     self.np_random.uniform(low=-0.36, high=0.36, size=(2,)),\n",
    "                                     self.np_random.uniform(low=0.0096, high=0.024, size=(1,)),\n",
    "                                     self.np_random.uniform(low=-0.12, high=0.12, size=(2,))), axis=None)\n",
    "\n",
    "        self.init_run = True\n",
    "        self.time = 0\n",
    "        self.effort = 0\n",
    "        self.click = 0\n",
    "        self.time_mean = deque(maxlen=1000)\n",
    "        self.error_rate = deque(maxlen=1000)\n",
    "\n",
    "        # True values\n",
    "        self.cursorPos = [0, 0]\n",
    "        self.cursorVel = [0, 0]\n",
    "        self.targetPos = [0, 0]\n",
    "        self.targetVel = [0, 0]\n",
    "        self.handPos = [0, 0]\n",
    "\n",
    "        self.effortWeight = 1\n",
    "        self.timeWeight = 0\n",
    "        self.clickWeight = 14\n",
    "        self.clickFailWeight = -1\n",
    "\n",
    "    def seed(self, seed=7):\n",
    "        self.np_random, seed = seeding.np_random(seed)\n",
    "        return [seed]\n",
    "\n",
    "    def step(self, action):\n",
    "        assert self.action_space.contains(action), \"%r (%s) invalid\" % (action, type(action))\n",
    "\n",
    "        # State space\n",
    "        c_pos_x, c_pos_y, c_vel_x, c_vel_y, t_pos_x, t_pos_y, t_vel_x, t_vel_y, target_radius, h_pos_x, h_pos_y = self.state\n",
    "\n",
    "        # Initial distance and speed\n",
    "        if self.init_run:\n",
    "            self.time = 0\n",
    "            self.effort = 0\n",
    "            self.click = 0\n",
    "            self.init_run = False\n",
    "\n",
    "            # Mouse clutching\n",
    "            hand_boundary = (self.forearm / 2)\n",
    "            hand_dist = (h_pos_x ** 2 + h_pos_y ** 2) ** 0.5\n",
    "            if hand_dist > hand_boundary:\n",
    "                clutch_time = np.random.normal(0.1898, 0.079, 1)[0]\n",
    "                if clutch_time < 0: clutch_time = 0\n",
    "                clutch_idx = int(np.ceil(clutch_time / self.Interval))\n",
    "\n",
    "                # User value\n",
    "                t_vel_x, t_vel_y = visual.visual_speed_noise(self.targetVel[0], self.targetVel[1])\n",
    "                t_pos_x, t_vel_x = motor.boundary(clutch_idx, t_pos_x, t_vel_x, self.Interval, self.window_width, target_radius)\n",
    "                t_pos_y, t_vel_y = motor.boundary(clutch_idx, t_pos_y, t_vel_y, self.Interval, self.window_height, target_radius)\n",
    "                self.state = (self.cursorPos[0], self.cursorPos[1], 0, 0, t_pos_x, t_pos_y, t_vel_x, t_vel_y, target_radius, 0, 0)\n",
    "\n",
    "                # True value\n",
    "                self.targetPos[0], self.targetVel[0] = motor.boundary(clutch_idx, self.targetPos[0], self.targetVel[0], self.Interval, self.window_width, target_radius)\n",
    "                self.targetPos[1], self.targetVel[1] = motor.boundary(clutch_idx, self.targetPos[1], self.targetVel[1], self.Interval, self.window_height, target_radius)\n",
    "                self.cursorVel = [0, 0]\n",
    "                self.handPos = [0, 0]\n",
    "\n",
    "                reward = -(self.timeWeight * clutch_time)\n",
    "                done = False\n",
    "                return np.array(self.state), reward, done, {}\n",
    "\n",
    "        # Action space\n",
    "        threshold_id = self.ThresholdID[action // len(self.Th)]\n",
    "        th = int(round(self.Th[action % len(self.Th)] / self.Interval))\n",
    "        tp = int(round(self.Tp / self.Interval))\n",
    "\n",
    "        # Input of the Point-and-Click model\n",
    "        state_true = self.cursorPos[0], self.cursorPos[1], self.targetPos[0], self.targetPos[1], self.targetVel[0], self.targetVel[1], target_radius, self.handPos[0], self.handPos[1]\n",
    "        state_cog = c_pos_x, c_pos_y, c_vel_x, c_vel_y\n",
    "        para_bump = th, tp, self.nc, self.fixed\n",
    "        para_icp = threshold_id, self.cMu, self.cSigma, self.nu, self.delta, self.p\n",
    "        para_env = self.Interval, self.window_width, self.window_height, self.forearm\n",
    "\n",
    "        # Point-and-Click model\n",
    "        c_otg_dx, c_otg_dy, c_otg_vel_x, c_otg_vel_y, time_click, cursor_delta, effort, h_pos_x, h_pos_y, vel_p, target_info, hand_delta = \\\n",
    "            pac.model(state_true, state_cog, para_bump, para_icp, para_env)\n",
    "\n",
    "        active_time = len(c_otg_dx) * self.Interval\n",
    "        time_reward = -(self.timeWeight * active_time)\n",
    "        effort_reward = -(self.effortWeight * effort)\n",
    "        click_reward = 0\n",
    "        done = False\n",
    "\n",
    "        # If the click is executed\n",
    "        if time_click <= active_time:\n",
    "            index_of_click_timing = math.floor(time_click / self.Interval)\n",
    "            time1 = (time_click / self.Interval) - index_of_click_timing\n",
    "\n",
    "            if index_of_click_timing == 0:\n",
    "                cursor_pos_x = self.cursorPos[0] + time1 * c_otg_dx[0]\n",
    "                cursor_pos_y = self.cursorPos[1] + time1 * c_otg_dy[0]\n",
    "            else:\n",
    "                cursor_pos_x = self.cursorPos[0] + np.sum(c_otg_dx[:index_of_click_timing]) + time1 * c_otg_dx[index_of_click_timing]\n",
    "                cursor_pos_y = self.cursorPos[1] + np.sum(c_otg_dy[:index_of_click_timing]) + time1 * c_otg_dy[index_of_click_timing]\n",
    "\n",
    "            target_pos_x, temp_vel_x = motor.boundary(index_of_click_timing, self.targetPos[0], self.targetVel[0], self.Interval, self.window_width, target_radius)\n",
    "            target_pos_x += time1 * self.Interval * temp_vel_x\n",
    "            target_pos_y, temp_vel_y = motor.boundary(index_of_click_timing, self.targetPos[1], self.targetVel[1], self.Interval, self.window_height, target_radius)\n",
    "            target_pos_y += time1 * self.Interval * temp_vel_y\n",
    "\n",
    "            dist_target_cursor = ((target_pos_x - cursor_pos_x) ** 2 + (target_pos_y - cursor_pos_y) ** 2) ** 0.5\n",
    "\n",
    "            time_reward = -(self.timeWeight * time_click)\n",
    "            effort_reward = -(self.effortWeight * effort)\n",
    "            done = True\n",
    "            self.time += time_click\n",
    "            self.time_mean.append(self.time)\n",
    "            self.effort += effort\n",
    "\n",
    "            if dist_target_cursor < target_radius:\n",
    "                click_reward = self.clickWeight\n",
    "                self.click = click_reward\n",
    "                self.error_rate.append(1)\n",
    "            else:\n",
    "                click_reward = self.clickFailWeight\n",
    "                self.click = click_reward\n",
    "                self.error_rate.append(0)\n",
    "\n",
    "        # User values\n",
    "        c_pos_x = self.cursorPos[0] + cursor_delta[0]\n",
    "        c_pos_y = self.cursorPos[1] + cursor_delta[1]\n",
    "        c_vel_x = vel_p[0]\n",
    "        c_vel_y = vel_p[1]\n",
    "        t_pos_x, t_vel_x = motor.boundary(len(c_otg_dx), target_info[0], target_info[2], self.Interval, self.window_width, target_radius)\n",
    "        t_pos_y, t_vel_y = motor.boundary(len(c_otg_dy), target_info[1], target_info[3], self.Interval, self.window_height, target_radius)\n",
    "        h_pos_x_ideal = self.handPos[0] + hand_delta[0]\n",
    "        h_pos_y_ideal = self.handPos[1] + hand_delta[1]\n",
    "\n",
    "        # Default\n",
    "        self.state = (c_pos_x, c_pos_y, c_vel_x, c_vel_y, t_pos_x, t_pos_y, t_vel_x, t_vel_y, target_radius, h_pos_x_ideal, h_pos_y_ideal)\n",
    "\n",
    "        # True values\n",
    "        self.cursorPos[0] += np.sum(c_otg_dx)\n",
    "        self.cursorPos[1] += np.sum(c_otg_dy)\n",
    "        self.cursorVel[0] = c_otg_vel_x[-1]\n",
    "        self.cursorVel[1] = c_otg_vel_y[-1]\n",
    "        self.targetPos[0], self.targetVel[0] = motor.boundary(len(c_otg_dx), self.targetPos[0], self.targetVel[0], self.Interval, self.window_width, target_radius)\n",
    "        self.targetPos[1], self.targetVel[1] = motor.boundary(len(c_otg_dy), self.targetPos[1], self.targetVel[1], self.Interval, self.window_height, target_radius)\n",
    "        self.handPos = [h_pos_x, h_pos_y]\n",
    "\n",
    "        # Final reward\n",
    "        reward = time_reward + effort_reward + click_reward\n",
    "\n",
    "        if time_click > active_time:\n",
    "            self.time += active_time\n",
    "            self.effort += effort\n",
    "\n",
    "        return np.array(self.state), reward, done, {}\n",
    "\n",
    "    def reset(self):\n",
    "        cp_x, cp_y, cv_x, cv_y, _, _, _, _, _, hp_x, hp_y = self.state\n",
    "        self.targetPos = np.concatenate((self.np_random.uniform(low=0, high=self.window_width, size=(1,)),\n",
    "                          self.np_random.uniform(low=0, high=self.window_height, size=(1,))), axis=None)\n",
    "        self.targetVel = self.np_random.uniform(low=-0.36, high=0.36, size=(2,))\n",
    "        target_radius = self.np_random.uniform(low=0.0096, high=0.024, size=(1,))\n",
    "        tp = int(round(self.Tp / self.Interval))\n",
    "\n",
    "        tp_x, tv_x = motor.boundary(tp, self.targetPos[0], -self.targetVel[0], self.Interval, self.window_width, target_radius)\n",
    "        tp_y, tv_y = motor.boundary(tp, self.targetPos[1], -self.targetVel[1], self.Interval, self.window_height, target_radius)\n",
    "        tv_x, tv_y = visual.visual_speed_noise(-tv_x, -tv_y)\n",
    "        tp_x, tv_x = motor.boundary(tp, tp_x, tv_x, self.Interval, self.window_width, target_radius)\n",
    "        tp_y, tv_y = motor.boundary(tp, tp_y, tv_y, self.Interval, self.window_height, target_radius)\n",
    "\n",
    "        self.state = np.concatenate((cp_x, cp_y, cv_x, cv_y, tp_x, tp_y, tv_x, tv_y, target_radius, hp_x, hp_y), axis=None)\n",
    "        self.init_run = True\n",
    "        self.time = 0\n",
    "        return np.array(self.state)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\user\\desktop\\mulitagent_pointandclick\\venv\\lib\\site-packages\\gym\\logger.py:30: UserWarning: \u001B[33mWARN: Box bound precision lowered by casting to float32\u001B[0m\n",
      "  warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    }
   ],
   "source": [
    "env = Env()\n",
    "\n",
    "# Constants defining our neural network\n",
    "INPUT_SIZE = env.observation_space.shape[0]\n",
    "OUTPUT_SIZE = env.action_space.n\n",
    "PATH_TO_MODEL = 'C:/Users/User/Desktop/prof_model'\n",
    "MAX_TEST_EPISODES = 1600\n",
    "GROUPING_SIZE = 200\n",
    "\n",
    "# csv\n",
    "user = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\User\\Desktop\\MulitAgent_PointAndClick\\deep_q_network.py:43: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\User\\Desktop\\MulitAgent_PointAndClick\\deep_q_network.py:44: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\User\\Desktop\\MulitAgent_PointAndClick\\deep_q_network.py:46: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.Dense instead.\n",
      "WARNING:tensorflow:From c:\\users\\user\\desktop\\mulitagent_pointandclick\\venv\\lib\\site-packages\\tensorflow_core\\python\\layers\\core.py:187: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `layer.__call__` method instead.\n",
      "WARNING:tensorflow:From C:\\Users\\User\\Desktop\\MulitAgent_PointAndClick\\deep_q_network.py:51: The name tf.losses.mean_squared_error is deprecated. Please use tf.compat.v1.losses.mean_squared_error instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\users\\user\\desktop\\mulitagent_pointandclick\\venv\\lib\\site-packages\\tensorflow_core\\python\\ops\\losses\\losses_impl.py:121: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From C:\\Users\\User\\Desktop\\MulitAgent_PointAndClick\\deep_q_network.py:53: The name tf.train.AdamOptimizer is deprecated. Please use tf.compat.v1.train.AdamOptimizer instead.\n",
      "\n",
      "INFO:tensorflow:Restoring parameters from C:/Users/User/Desktop/prof_model/model\n"
     ]
    }
   ],
   "source": [
    "# store the previous observations in replay memory\n",
    "replay_buffer = []\n",
    "\n",
    "tf.disable_eager_execution()\n",
    "sess = tf.Session()\n",
    "mainDQN = dqn.DQN(sess, INPUT_SIZE, OUTPUT_SIZE, name=\"main\")\n",
    "new_saver = tf.train.import_meta_graph(f'{PATH_TO_MODEL}/model.meta')\n",
    "new_saver.restore(sess, tf.train.latest_checkpoint(f'{PATH_TO_MODEL}/'))\n",
    "# sess.run(tf.global_variables_initializer())\n",
    "# mainDQN.load(PATH_TO_MODEL)\n",
    "\n",
    "for episode in range(MAX_TEST_EPISODES):\n",
    "        done = False\n",
    "        state = env.reset()\n",
    "        replay_buffer.append((env.time, user, (episode+1)//GROUPING_SIZE, (episode+1)%GROUPING_SIZE, env.cursorPos[0], env.cursorPos[1], env.targetPos[0], env.targetPos[1], state[8], (env.targetVel[0]**2 + env.targetVel[1]**2) ** 0.5, 0, 0))\n",
    "\n",
    "        while not done:\n",
    "            # Get the q table\n",
    "            q_values = mainDQN.predict(state)\n",
    "\n",
    "            # Get the action\n",
    "            action = np.argmax(q_values)\n",
    "\n",
    "            # Get new state and reward from environment\n",
    "            next_state, reward, done, _ = env.step(action)\n",
    "\n",
    "            state = next_state\n",
    "\n",
    "            replay_buffer.append((env.time, user, (episode+1)//GROUPING_SIZE, (episode+1)%GROUPING_SIZE, env.cursorPos[0], env.cursorPos[1], env.targetPos[0], env.targetPos[1], state[8], (env.targetVel[0]**2 + env.targetVel[1]**2) ** 0.5, 1 if done else 0, 1 if done and env.click == 14 else 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "replay_buffer = pd.DataFrame(replay_buffer, columns=['time', 'user', 'task', 'trial', 'cursor_x', 'cursor_y', 'target_x', 'target_y', 'target_radius', 'target_speed', 'click_action', 'click_success'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "replay_buffer.to_csv('trajectory.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}